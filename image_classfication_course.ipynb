{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e52bc1-d35c-4534-9296-c3a15d22e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade torch torchvision torchdata  torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245afec3-fd67-4a43-ad94-a4d6a2adaea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.6.0+cu124\n",
      "torchvision version: 0.21.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ed4054-2268-4cd3-b038-124c20cfb4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Continue with regular imports\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# Try to get torchinfo, install it if it doesn't work\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary\n",
    "\n",
    "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
    "try:\n",
    "    from going_modular.going_modular import data_setup, engine\n",
    "except:\n",
    "    # Get the going_modular scripts\n",
    "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
    "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
    "    !mv pytorch-deep-learning/going_modular .\n",
    "    !rm -rf pytorch-deep-learning\n",
    "    from going_modular.going_modular import data_setup, engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9354a54-e961-43db-8d67-294b5c2e893a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb17c652-6aa6-41c4-b5ed-3fcada3420d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "943e96b7-d8c9-4039-b763-81c737cfb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "data_path = Path(\"data/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f6c171-731f-44fe-897b-04fc38e4448b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0757eab-8f43-417e-a521-963dc146a533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/images_data.zip')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "target_file= \"images_data.zip\"\n",
    "source=data_path / target_file\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27895055-d54a-4585-b965-71268682f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = Path(\"data\")\n",
    "\n",
    "# # Unzip pizza, steak, sushi data\n",
    "# with zipfile.ZipFile(source, \"r\") as zip_ref:\n",
    "#     zip_ref.extractall(image_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db5dfa1a-cf4b-4a2e-9113-982264fdd3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/version2/train')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Setup directories\n",
    "image_path = Path(\"data/version2\")\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a0598d9-2b1c-4a58-9b47-c3c55cb97a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created transforms: ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BICUBIC\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f319c1c3550>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f319dd79c60>,\n",
       " ['airplane', 'car', 'cat', 'dog', 'flower', 'motorbike', 'person'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup ImageNet normalization levels (turns all images into similar distribution as ImageNet)\n",
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# # Create transform pipeline manually\n",
    "# manual_transforms = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     normalize\n",
    "# ])\n",
    "\n",
    "# print(f\"Manually created transforms: {manual_transforms}\")\n",
    "\n",
    "# image_size=(224,224)\n",
    "# transforms_train = transforms.Compose([transforms.ToPILImage(),\n",
    "#                                        transforms.Resize(image_size),\n",
    "#                                        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
    "#                                        transforms.RandomHorizontalFlip(p=0.5),\n",
    "#                                        transforms.RandomVerticalFlip(p=0.1),\n",
    "#                                        transforms.RandomRotation(degrees=30),\n",
    "#                                        transforms.ToTensor()\n",
    "#                                        ])\n",
    "\n",
    "# transforms_test = transforms.Compose([transforms.ToPILImage(),\n",
    "#                                       transforms.Resize(image_size),\n",
    "#                                       transforms.ToTensor()\n",
    "#                                        ])\n",
    "\n",
    "\n",
    "# Setup pretrained weights (plenty of these available in torchvision.models)\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "# Get transforms from weights (these are the transforms that were used to obtain the weights)\n",
    "automatic_transforms = weights.transforms() \n",
    "print(f\"Automatically created transforms: {automatic_transforms}\")\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    #transform=automatic_transforms, # use automatic created transforms\n",
    "    transforms_train=automatic_transforms, # use automatic created transforms\n",
    "    transforms_test=automatic_transforms, # use automatic created transforms\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af846806-763a-468d-b08d-af5b3b29f2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane', 'car', 'cat', 'dog', 'flower', 'motorbike', 'person']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bf2dca2-5c9b-47d4-9292-32452cad12c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /home/workbench/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|██████████| 20.5M/20.5M [00:00<00:00, 28.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Note: This is how a pretrained model would be created in torchvision > 0.13, it will be deprecated in future versions.\n",
    "# model = torchvision.models.efficientnet_b0(pretrained=True).to(device) # OLD \n",
    "\n",
    "# Download the pretrained weights for EfficientNet_B0\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # NEW in torchvision 0.13, \"DEFAULT\" means \"best weights available\"\n",
    "\n",
    "# Setup the model with the pretrained weights and send it to the target device\n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "\n",
    "# View the output of the model\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae2b02b-3a41-4d97-b35f-394a94d1bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().system_raw(\"mlflow ui --port 5000 &\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "446dc95b-9225-4408-a90f-0b600c659068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54ad4376-4595-453f-8716-33540948e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrok.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30aa7a9f-993c-4051-8b7c-cacfe1dceefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ngrok: 30%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-02-07 05:39:36 +0000] [4073] [INFO] Starting gunicorn 23.0.0\n",
      "[2025-02-07 05:39:36 +0000] [4073] [INFO] Listening at: http://127.0.0.1:5000 (4073)\n",
      "[2025-02-07 05:39:36 +0000] [4073] [INFO] Using worker: sync\n",
      "[2025-02-07 05:39:36 +0000] [4074] [INFO] Booting worker with pid: 4074\n",
      "[2025-02-07 05:39:36 +0000] [4075] [INFO] Booting worker with pid: 4075\n",
      "[2025-02-07 05:39:36 +0000] [4076] [INFO] Booting worker with pid: 4076\n",
      "[2025-02-07 05:39:36 +0000] [4077] [INFO] Booting worker with pid: 4077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /home/workbench/.config/ngrok/ngrok.yml                      \n"
     ]
    }
   ],
   "source": [
    "!ngrok config add-authtoken 2sVwQYmf9x00hLx9OsT04T4Vk1R_3gyuN842eLrdSZYgebt5F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f651bd16-00bc-4594-8036-47016769156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1d5d781-22ab-47f0-848b-cffa02fea4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow UI  https://fd50-67-254-220-141.ngrok-free.app\n"
     ]
    }
   ],
   "source": [
    "print(\"MLflow UI \", ngrok_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "414e3070-e0fd-47e2-8cb3-068f6a4f28de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1400\"\n",
       "            height=\"600\"\n",
       "            src=\"https://fd50-67-254-220-141.ngrok-free.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f302fa094b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "url = ngrok_tunnel.public_url\n",
    "IFrame(url, width=1400, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599b38d-2230-4641-8c8c-cb1e503c60da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2049a70f-493d-415d-bc4d-a7f5fc29c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all base layers by setting requires_grad attribute to False\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Since we're creating a new layer with random weights (torch.nn.Linear), \n",
    "# let's set the seeds\n",
    "set_seeds() \n",
    "\n",
    "# Update the classifier head to suit our problem\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, \n",
    "              out_features=len(class_names),\n",
    "              bias=True).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7a14ac7-65d1-4303-a26b-239a223b6333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f18af15f-a826-461b-aa2c-d9fa1054241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c212898-0669-4ea1-bcbb-9c257c58e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find tensorboard... installing it.\")\n",
    "    !pip install -q tensorboard\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# Create a writer with all default settings\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a865cb15-ab04-433d-a299-33029c0f37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Tuple, Dict  # Type hinting for clarity\n",
    "from going_modular.going_modular.engine import train_step, test_step\n",
    "\n",
    "# Import train() function from: \n",
    "# https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/engine.py\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]: \n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "    Args:\n",
    "      model: A PyTorch model to be trained and tested.\n",
    "      train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "      test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "      optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "      loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "      epochs: An integer indicating how many epochs to train for.\n",
    "      device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "      \n",
    "    Returns:\n",
    "      A dictionary of training and testing loss as well as training and\n",
    "      testing accuracy metrics. Each metric has a value in a list for \n",
    "      each epoch.\n",
    "      In the form: {train_loss: [...],\n",
    "                train_acc: [...],\n",
    "                test_loss: [...],\n",
    "                test_acc: [...]} \n",
    "      For example if training for epochs=2: \n",
    "              {train_loss: [2.0616, 1.0537],\n",
    "                train_acc: [0.3945, 0.3945],\n",
    "                test_loss: [1.2641, 1.5706],\n",
    "                test_acc: [0.3400, 0.2973]} \n",
    "    \"\"\"\n",
    " \n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "    }\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        device=device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    " \n",
    "\n",
    "        ### New: Experiment tracking ###\n",
    "        # Add loss results to SummaryWriter\n",
    "        writer.add_scalars(main_tag=\"Loss\", \n",
    "                           tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                            \"test_loss\": test_loss},\n",
    "                           global_step=epoch)\n",
    "\n",
    "        # Add accuracy results to SummaryWriter\n",
    "        writer.add_scalars(main_tag=\"Accuracy\", \n",
    "                           tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                            \"test_acc\": test_acc}, \n",
    "                           global_step=epoch)\n",
    "        \n",
    "        # Track the PyTorch model architecture\n",
    "        writer.add_graph(model=model, \n",
    "                         # Pass in an example input\n",
    "                         input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
    "    \n",
    "    # Close the writer\n",
    "    writer.close()\n",
    "    \n",
    "    ### End new ###\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed626574-e4f5-411f-8356-2b66d5abe169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import yaml\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90acfdfa-ee96-45d8-a35c-909fcb1128f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_experiment_name():\n",
    "    \"\"\"Generate a random experiment name.\"\"\"\n",
    "    prefix = \"experiment\"\n",
    "    random_suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))\n",
    "    return f\"{prefix}-{random_suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6862dd06-e12a-46f9-867d-5e8b67e078aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/07 05:47:47 INFO mlflow.tracking.fluent: Experiment with name 'experiment-0z2i5zza' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment-0z2i5zza\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.7861 | train_acc: 0.4292 | test_loss: 1.5758 | test_acc: 0.7083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:08<00:33,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 1.3432 | train_acc: 0.8479 | test_loss: 1.2386 | test_acc: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:15<00:22,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.9790 | train_acc: 0.9500 | test_loss: 0.9561 | test_acc: 0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:23<00:15,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.7770 | train_acc: 0.9771 | test_loss: 0.7671 | test_acc: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:30<00:07,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.5903 | train_acc: 1.0000 | test_loss: 0.6403 | test_acc: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:39<00:00,  7.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: models/experiment-0z2i5zza.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/07 05:48:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\n",
      "CPU times: user 21.8 s, sys: 17.7 s, total: 39.6 s\n",
      "Wall time: 49.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from going_modular.going_modular.utils import save_model\n",
    "#mlflow.pytorch.autolog()\n",
    "\n",
    "#mlflow set experiement\n",
    "#mlflow.tracking.set_tracking_uri(\"https://a1e3-67-254-220-141.ngrok-free.app/\")\n",
    "experiment_name=generate_random_experiment_name()\n",
    "print(experiment_name)\n",
    "mlflow.set_experiment(experiment_name=experiment_name)\n",
    "\n",
    "\n",
    "# 1. Set the random seeds\n",
    "set_seeds(seed=42)\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name = f\"{experiment_name}-run\") as run:  \n",
    "    results = train(model=model,\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    test_dataloader=test_dataloader,\n",
    "                    optimizer=optimizer,\n",
    "                    loss_fn=loss_fn,\n",
    "                    epochs=5,\n",
    "                    device=device)\n",
    "    # print(results)\n",
    "    for key, values in results.items():\n",
    "        for i, val in enumerate(values, start=1): # start=1 makes the index start at 1\n",
    "            mlflow.log_metric(key,val, step=i, synchronous=False)\n",
    "\n",
    "    # 10. Save the model to file so we can get back the best model\n",
    "    save_filepath = f\"{experiment_name}.pth\"\n",
    "    mlflow.log_param(\"save_filepath\", save_filepath)\n",
    "    save_model(model=model,\n",
    "               target_dir=\"models\",\n",
    "               model_name=save_filepath)\n",
    "    mlflow.pytorch.log_model(model, \"models\")\n",
    "        \n",
    "mlflow.end_run()\n",
    "print(\"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ce6cd9d-fe15-4fa2-bea5-21b3d1923c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [1.7860800743103027,\n",
       "  1.3431644201278687,\n",
       "  0.9789897680282593,\n",
       "  0.777011489868164,\n",
       "  0.5903068900108337],\n",
       " 'train_acc': [0.4291666666666667,\n",
       "  0.8479166666666667,\n",
       "  0.95,\n",
       "  0.9770833333333334,\n",
       "  1.0],\n",
       " 'test_loss': [1.5757891178131103,\n",
       "  1.238572120666504,\n",
       "  0.9560967803001403,\n",
       "  0.7671110212802887,\n",
       "  0.6403304934501648],\n",
       " 'test_acc': [0.7083333333333333, 0.9375, 0.9625, 0.96875, 0.96875]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a130a-7e2a-4efc-97e5-77e4c5fc3b34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
